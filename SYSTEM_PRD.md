# Comprehensive Project Requirements Document (PRD): High-Performance Proxy Management System

## 1. Introduction & Objectives
The **High-Performance Proxy Management System** (Ver 6.0) is a robust, asynchronous backend solution built to provide a continuous stream of high-quality, verified public proxies. 

The primary objectives are:
- **Total Automation**: Zero manual intervention for proxy gathering and cleaning.
- **Ultra-High Availability**: Ensuring that any proxy in the database is functional at any given moment.
- **Stability Recognition**: Identifying and segregating "stable" proxies that have long lifespans into a dedicated VIP pool.

---

## 2. Technical System Architecture
The system is built on an **Asynchronous Triple-Loop Architecture** powered by Python's `asyncio` and `aiohttp`. This allows the script to handle thousands of network connections concurrently without significant overhead.

### 2.1 The Fetcher Loop (Discovery)
- **Primary Source**: ScrapeProxy API V4 (Bulk mode).
- **Interval**: Every 20 seconds.
- **Logic**: 
    - Pulls up to 2000 raw proxies.
    - Filters out duplicates against a local cache of the database.
    - Performs an immediate "Pre-validation" health check.
    - Only "Working" proxies are pushed to the Firebase `/proxies` path.

### 2.2 The Cleanup Loop (Sanitization)
- **Target**: Both `/proxies` and `/stable_proxies` paths.
- **Interval**: Continuous (2-second delay between full scans).
- **Logic**: 
    - Scans every entry in the database.
    - Uses a 10-second timeout to check availability.
    - **Immediate Purge**: If a proxy fails a single check, it is deleted from its respective pool immediately. 
    - This ensures the database never contains "dead" entries for more than a few seconds.

### 2.3 The Stability Monitor Loop (Promotion)
- **Target**: Main `/proxies` pool.
- **Interval**: Every 30 seconds.
- **Logic**:
    - Calculates the "Age" of each proxy (`Current Time - Created At`).
    - **Promotion Threshold**: 10 minutes (600 seconds).
    - Proxies meeting the threshold are copied to the `/stable_proxies` pool.
    - This creates a filtered "VIP" list for users who need maximum reliability.

---

## 3. Database Structure & Data Schema
The system uses **Firebase Realtime Database** for centralized, low-latency storage. Below is the exact JSON structure of the data.

### 3.1 Main Pool (`/proxies`)
This is the incoming pool. Entries are stored as key-value pairs where the key is a unique ID generated by Firebase.

**Example Structure:**
```json
{
  "-Nxyz123abc": {
    "address": "101.47.16.15:7890",
    "status": "active",
    "created_at": 1704723145.5,
    "last_checked": 1704723500.2
  },
  "-Nabc456def": {
    "address": "108.162.192.147:80",
    "status": "active",
    "created_at": 1704723150.1,
    "last_checked": 1704723505.8
  }
}
```

### 3.2 Stable Pool (`/stable_proxies`)
Promoted proxies that have survived the 10-minute threshold.

**Example Structure:**
```json
{
  "-Msta789ghi": {
    "address": "101.47.16.15:7890",
    "age_seconds": 605.5,
    "original_key": "-Nxyz123abc",
    "promoted_at": 1704723745.5
  }
}
```

---

## 4. Developer & AI Integration Guide
Any external application or AI Agent can consume these proxies via simple HTTP GET requests.

### 4.1 Access Endpoints
- **Main JSON (Standard)**: `https://clous-proxys-qpi-default-rtdb.firebaseio.com/proxies.json`
- **Stable JSON (Premium)**: `https://clous-proxys-qpi-default-rtdb.firebaseio.com/stable_proxies.json`

### 4.2 Implementation Example (fetching a list)
```python
import requests

def fetch_working_proxies():
    # Recommended: always use the stable pool for better performance in your app
    url = "https://clous-proxys-qpi-default-rtdb.firebaseio.com/stable_proxies.json"
    response = requests.get(url)
    
    if response.status_code == 200:
        data = response.json()
        if data:
            # list of strings: ["IP:PORT", "IP:PORT", ...]
            return [v['address'] for v in data.values()]
    return []

# Usage for an AI agent:
# 1. Fetch the list.
# 2. Pick one random address.
# 3. Setup your 'proxies' dictionary for the requests library.
```

---

## 5. Performance Metrics
- **Max Concurrency**: 200 simultaneous requests (managed via Semaphores).
- **Health Check Target**: `http://httpbin.org/ip` (Fast and reliable global target).
- **Timeout Policy**: 10 seconds (Strict but allows high-latency proxies to stay functional).

---

## 6. Self-Healing & Maintenance
The system requires **Zero Maintenance**.
- **Auto-Scale**: Handles pool sizes from 10 to 10,000 proxies without performance degradation.
- **Auto-Sanitize**: If the Stable Pool contains a proxy that eventually dies, the **Cleanup Loop** will detect and remove it within minutes.
- **Deployment Ready**: Fully compatible with Render Background Workers (running 24/7).
